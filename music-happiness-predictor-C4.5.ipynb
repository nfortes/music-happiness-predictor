{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09597393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Filter for simplicity - top 5 most common genres\n",
    "top_genres = df['track_genre'].value_counts().nlargest(5).index\n",
    "df = df[df['track_genre'].isin(top_genres)]\n",
    "\n",
    "# Select relevant features\n",
    "features = ['danceability', 'energy', 'acousticness', 'instrumentalness', 'valence', 'tempo']\n",
    "X = df[features]\n",
    "y = df['track_genre']\n",
    "\n",
    "# Discretize continuous features (e.g. using quartiles)\n",
    "for col in X.columns:\n",
    "    X[col] = pd.qcut(X[col], q=4, labels=False, duplicates='drop')\n",
    "\n",
    "# Combine for easier handling\n",
    "df = X.copy()\n",
    "df['label'] = y\n",
    "\n",
    "# --- C4.5 Functions ---\n",
    "def entropy(labels):\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "    return -sum((count/total) * math.log2(count/total) for count in counts.values())\n",
    "\n",
    "def info_gain_ratio(df, attr, target):\n",
    "    total_entropy = entropy(df[target])\n",
    "    values = df[attr].unique()\n",
    "    splits = []\n",
    "    split_info = 0\n",
    "    weighted_entropy = 0\n",
    "\n",
    "    for val in values:\n",
    "        subset = df[df[attr] == val]\n",
    "        prob = len(subset) / len(df)\n",
    "        weighted_entropy += prob * entropy(subset[target])\n",
    "        split_info -= prob * math.log2(prob) if prob > 0 else 0\n",
    "\n",
    "    gain = total_entropy - weighted_entropy\n",
    "    return gain / split_info if split_info != 0 else 0\n",
    "\n",
    "def build_tree(df, target, features):\n",
    "    labels = df[target]\n",
    "    if len(set(labels)) == 1:\n",
    "        return labels.iloc[0]\n",
    "    if len(features) == 0:\n",
    "        return labels.mode()[0]\n",
    "\n",
    "    gains = {feature: info_gain_ratio(df, feature, target) for feature in features}\n",
    "    best_feature = max(gains, key=gains.get)\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    for val in df[best_feature].unique():\n",
    "        subset = df[df[best_feature] == val]\n",
    "        subtree = build_tree(subset, target, [f for f in features if f != best_feature])\n",
    "        tree[best_feature][val] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "def predict(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    attr = next(iter(tree))\n",
    "    val = sample[attr]\n",
    "    subtree = tree[attr].get(val)\n",
    "    if subtree is None:\n",
    "        return None\n",
    "    return predict(subtree, sample)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df['label'], test_size=0.2, random_state=42)\n",
    "train_df = X_train.copy()\n",
    "train_df['label'] = y_train\n",
    "\n",
    "# Train tree\n",
    "decision_tree = build_tree(train_df, 'label', features)\n",
    "\n",
    "# Predict\n",
    "y_pred = [predict(decision_tree, row) for _, row in X_test.iterrows()]\n",
    "\n",
    "# Remove Nones from unknowns\n",
    "valid_idx = [i for i, val in enumerate(y_pred) if val is not None]\n",
    "accuracy = accuracy_score(y_test.iloc[valid_idx], [y_pred[i] for i in valid_idx])\n",
    "print(\"C4.5-style Decision Tree Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
