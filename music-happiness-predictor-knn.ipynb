{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course : CS 513 - Knowledge Discovery and Data Mining\n",
    "# Group Members: Branden Bulatao, Joseph Faustino, Natalie Fortes, Isabel Sutedjo\n",
    "# Id : 20005971\n",
    "# Purpose : Music Happiness Predictor - Predicts the happiness of music tracks based on various features.\n",
    "\n",
    "# Main Author: Branden Bulatao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clips outliers Q1–1.5×IQR and Q3+1.5×IQR\n",
    "def clip_outliers(df, feature):\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Clip the values\n",
    "    df[feature] = df[feature].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "    # sns.boxplot(x=f\"{feature}\", data=df)\n",
    "    # plt.title(f\"{feature} by Valence Group\")\n",
    "    # plt.show()\n",
    "    return df\n",
    "\n",
    "def clip_outliers_strict(df, feature):\n",
    "    lower = df[feature].quantile(0.005)\n",
    "    upper = df[feature].quantile(0.995)\n",
    "    df[feature] = df[feature].clip(lower=lower, upper=upper)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Check Outlier percentages of each feature\n",
    "def calculate_outlier_percentage(df, feature):\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "    outlier_percentage = len(outliers) / len(df) * 100\n",
    "    return outlier_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv(\"./dataset.csv\")\n",
    "\n",
    "df.drop(\n",
    "    df.columns[df.columns.str.contains(\"unnamed\", case=False)], axis=1, inplace=True\n",
    ")  # drop unnamed column\n",
    "\n",
    "df.dropna(inplace=True)  # drop rows with null values\n",
    "\n",
    "df[\"valence\"] = df[\"valence\"].astype(\"category\")\n",
    "df[\"valence\"] = df[\"valence\"].map(\n",
    "    lambda x: 0 if x < 0.5 else 1\n",
    ")  # sets valence to 0 if sad, 1 if happy\n",
    "\n",
    "# Convert 'explicit' boolean to integer (0/1)\n",
    "df[\"explicit\"] = df[\"explicit\"].astype(int)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(\n",
    "    df, columns=[\"key\", \"time_signature\", \"track_genre\"], drop_first=True\n",
    ")\n",
    "\n",
    "# X = df.drop(['track_id', 'artists', 'album_name', 'track_name', 'valence'], axis=1)\n",
    "X = df.drop([\"track_id\", \"artists\", \"album_name\", \"track_name\", \"valence\", \"duration_ms\"], axis=1)\n",
    "y = df[\"valence\"]\n",
    "\n",
    "# Identify numeric features to scale\n",
    "numeric_features = [\n",
    "    # \"duration_ms\",\n",
    "    # \"popularity\",\n",
    "    # \"tempo\",\n",
    "    # \"loudness\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"speechiness\",\n",
    "    \"acousticness\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "]\n",
    "\n",
    "numeric_high_value_features = [\n",
    "    \"popularity\",\n",
    "    \"tempo\",\n",
    "    \"loudness\",\n",
    "]\n",
    "\n",
    "# All other features (binary or one-hot) are left as-is\n",
    "non_scaled_features = [\n",
    "    col \n",
    "    for col in X.columns \n",
    "    if col not in (numeric_features + numeric_high_value_features)\n",
    "]\n",
    "# non_scaled_features = [col for col in X.columns if col not in numeric_high_value_features]\n",
    "\n",
    "# Clip extreme outliers >5%\n",
    "# threshold = 5\n",
    "# for col in numeric_features + numeric_high_value_features:\n",
    "#     percent = calculate_outlier_percentage(X, col)\n",
    "#     if percent > threshold:\n",
    "#         X = clip_outliers(X, col)\n",
    "#         print(f\"Clipped {col} (outliers were {percent:.2f}%)\")\n",
    "\n",
    "# ColumnTransformer for selective scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"num\", \"passthrough\", numeric_features),\n",
    "        (\"num2\", MinMaxScaler(), numeric_high_value_features),\n",
    "        (\"pass\", \"passthrough\", non_scaled_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Reconstruct a DataFrame (optional, for inspection/debugging)\n",
    "final_features = numeric_features + numeric_high_value_features + non_scaled_features\n",
    "X_processed = pd.DataFrame(X_processed, columns=final_features)\n",
    "# X_processed = X_processed.apply(pd.to_numeric)  # <-- this line fixes your problem\n",
    "\n",
    "# Train the code\n",
    "attr_train, attr_test, target_train, target_test = train_test_split(\n",
    "    X_processed, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_processed[numeric_features].describe())\n",
    "print(X_processed[numeric_high_value_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no clip 0.7279824561403508\n",
    "reg clip 0.725906432748538\n",
    "strict clip 0.7272222222222222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# K-nearest neighbors\n",
    "# k_values = [3, 5, 7, 10, 15, 20, 30]\n",
    "k_values = [20]\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    # knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn = KNeighborsClassifier(n_neighbors = k,weights='distance')\n",
    "    knn.fit(attr_train, target_train)\n",
    "    target_pred = knn.predict(attr_test)\n",
    "    # accuracy = round(np.mean(target_test==target_pred ) * 100, 2)\n",
    "\n",
    "    accuracy = accuracy_score(target_test, target_pred)\n",
    "    test_accuracies.append(knn.score(attr_test, target_test))\n",
    "\n",
    "\n",
    "    print(f\"Accuracy of model with k = {k}: {accuracy}\")\n",
    "    print(\"\")\n",
    "\n",
    "    scores = cross_val_score(knn, attr_train, target_train, cv=5)\n",
    "    print(\"Cross-validated Score:\", scores.mean())\n",
    "\n",
    "\n",
    "# Plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(k_values, test_accuracies, label='Test Accuracy', marker='s')\n",
    "# plt.xlabel('Number of Neighbors (k)')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('KNN Accuracy vs Number of Neighbors')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "accuracy = accuracy_score(target_test, target_pred)\n",
    "conf_matrix = confusion_matrix(target_test, target_pred)\n",
    "class_report = classification_report(target_test, target_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "test_actual = attr_test  # Copy attr_test\n",
    "test_actual[\"target_pred\"] = target_pred  # Create new column for prediction values\n",
    "test_actual[\"test_actual\"] = target_test  # Create new column for actual values\n",
    "test_actual.head()  # Show table\n",
    "\n",
    "misclassified = (\n",
    "    test_actual[\"target_pred\"] != test_actual[\"test_actual\"]\n",
    ").sum()  # Calculate number of misclassified cases\n",
    "total_tests = len(test_actual)  # total number of cases\n",
    "\n",
    "error_rate = misclassified / total_tests\n",
    "\n",
    "# Error rate percentage\n",
    "print(f\"Error rate: {error_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(target_test, target_pred)\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt=\"g\", cmap=\"Blues\", ax=ax)\n",
    "\n",
    "# Labels, title, and ticks\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"KNN Confusion Matrix for Valence\")\n",
    "ax.xaxis.set_ticklabels([\"Sad (0)\", \"Happy (1)\"])\n",
    "ax.yaxis.set_ticklabels([\"Sad (0)\", \"Happy (1)\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positives\n",
    "results = pd.DataFrame(X)  # make sure this matches your data\n",
    "\n",
    "test_actual = attr_test  # Copy attr_test\n",
    "test_actual[\"target_pred\"] = target_pred  # Create new column for prediction values\n",
    "test_actual[\"test_actual\"] = target_test  # Create new column for actual values\n",
    "# test_actual.head()  # Show table\n",
    "\n",
    "false_positives = test_actual[\n",
    "    (test_actual[\"target_pred\"] == 1) & (test_actual[\"test_actual\"] == 0)\n",
    "]\n",
    "\n",
    "false_negatives = test_actual[\n",
    "    (test_actual[\"target_pred\"] == 0) & (test_actual[\"test_actual\"] == 1)\n",
    "]\n",
    "\n",
    "true_positives = test_actual[\n",
    "    (test_actual[\"target_pred\"] == 1) & (test_actual[\"test_actual\"] == 1)\n",
    "]\n",
    "\n",
    "true_negatives = test_actual[\n",
    "    (test_actual[\"target_pred\"] == 0) & (test_actual[\"test_actual\"] == 0)\n",
    "]\n",
    "\n",
    "print(false_positives)\n",
    "print(false_negatives)\n",
    "# false_positives.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code given from the ML02_EDA.ipynb\n",
    "# # Summarize each column\n",
    "# summary_p = false_positives.describe().loc[[\"min\", \"max\", \"mean\"]]\n",
    "# summary_n = false_negatives.describe().loc[[\"min\", \"max\", \"mean\"]]\n",
    "\n",
    "# # Print the summary\n",
    "# print(summary_p)\n",
    "# print(summary_n)\n",
    "\n",
    "# print(\"\\n min, max, mean only\")\n",
    "# # Min_Max_Mean=df.describe(include=[float, int]).loc[[\"min\", \"max\", \"mean\"]]\n",
    "# Min_Max_Mean = X.describe(include=[float, int]).loc[[\"min\", \"max\", \"mean\"]]\n",
    "# print(Min_Max_Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"False Negatives Summary vs Full Dataset:\")\n",
    "# print(false_negatives.describe().loc[[\"mean\"]])\n",
    "# print(\"\\nFull Dataset:\")\n",
    "# print(df.describe().loc[[\"mean\"]])\n",
    "\n",
    "# delta_n = false_negatives.describe().loc[\"mean\"] - df.describe().loc[\"mean\"]\n",
    "# print(\"\\nDifference in Mean (False Negatives - Full Dataset):\")\n",
    "# print(delta_n)\n",
    "\n",
    "# delta_p = false_positives.describe().loc[\"mean\"] - df.describe().loc[\"mean\"]\n",
    "# print(\"\\nDifference in Mean (False Positives - Full Dataset):\")\n",
    "# print(delta_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_no_genres = df.loc[:, ~df.columns.str.contains(\"track_genre\")]\n",
    "\n",
    "feature_cols = [\n",
    "    col\n",
    "    for col in df_no_genres.columns\n",
    "    if col\n",
    "    not in [\n",
    "        \"target_actual\",\n",
    "        \"target_pred\",\n",
    "        \"track_id\",\n",
    "        \"artists\",\n",
    "        \"album_name\",\n",
    "        \"track_name\",\n",
    "        \"valence\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# KF_df = df.drop(columns=[\"valence\",\"duration_ms\"])\n",
    "print(df_no_genres.select_dtypes(include=[\"float\", \"int\"]).columns)\n",
    "for col in df_no_genres.select_dtypes(include=[\"float\", \"int\"]).columns:\n",
    "    if col == \"valence\" or col == \"duration_ms\": continue\n",
    "   \n",
    "    plt.figure(figsize=(6, 3))\n",
    "\n",
    "    # KDE plots\n",
    "    sns.kdeplot(false_negatives[col], label=\"False Negatives\", fill=True, color=\"r\")\n",
    "    sns.kdeplot(false_positives[col], label=\"False Positives\", fill=True, color=\"g\")\n",
    "    sns.kdeplot(true_positives[col], label=\"True Positives\", fill=True, color=\"royalblue\")\n",
    "    sns.kdeplot(true_negatives[col], label=\"True Negatives\", fill=True, color=\"y\")\n",
    "\n",
    "    # Vertical lines for means\n",
    "    plt.axvline(false_negatives[col].mean(), color=\"r\", linestyle=\"--\", label=\"FN Mean\")\n",
    "    plt.axvline(false_positives[col].mean(), color=\"g\", linestyle=\"--\", label=\"FP Mean\")\n",
    "    plt.axvline(\n",
    "        true_positives[col].mean(), color=\"royalblue\", linestyle=\"--\", label=\"TP Mean\"\n",
    "    )\n",
    "    plt.axvline(\n",
    "        true_negatives[col].mean(), color=\"gold\", linestyle=\"--\", label=\"TN Mean\"\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(type(false_negatives[col].mean()))\n",
    "\n",
    "    print(f\"Stats for '{col}':\")\n",
    "    print(f\"  False Negatives - mean: {false_negatives[col].mean():.4f}, std: {false_negatives[col].std():.4f}\")\n",
    "    print(f\"  False Positives - mean: {false_positives[col].mean():.4f}, std: {false_positives[col].std():.4f}\")\n",
    "    print(f\"  True Positives  - mean: {true_positives[col].mean():.4f}, std: {true_positives[col].std():.4f}\")\n",
    "    print(f\"  True Negatives  - mean: {true_negatives[col].mean():.4f}, std: {true_negatives[col].std():.4f}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "df_no_genres = df.loc[:, ~df.columns.str.contains(\"track_genre\")]\n",
    "\n",
    "# Features only (adjust as needed)\n",
    "feature_cols = [\n",
    "    col\n",
    "    for col in df_no_genres.columns\n",
    "    if col\n",
    "    not in [\n",
    "        \"target_actual\",\n",
    "        \"target_pred\",\n",
    "        \"track_id\",\n",
    "        \"artists\",\n",
    "        \"album_name\",\n",
    "        \"track_name\",\n",
    "        \"valence\",\n",
    "        \"duration_ms\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(feature_cols)\n",
    "\n",
    "# Mean summary per category\n",
    "summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"True Positives\": true_positives[feature_cols].mean(),\n",
    "        \"True Negatives\": true_negatives[feature_cols].mean(),\n",
    "        \"False Positives\": false_positives[feature_cols].mean(),\n",
    "        \"False Negatives\": false_negatives[feature_cols].mean(),\n",
    "        # \"All Data\": df[feature_cols].mean(),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Transpose for easier plotting\n",
    "summary_df = summary_df.astype(float)\n",
    "summary_df = summary_df.T\n",
    "\n",
    "# Optional: Normalize columns for radar/spider-style plots\n",
    "summary_norm = (summary_df - summary_df.min()) / (summary_df.max() - summary_df.min())\n",
    "\n",
    "# --- Plot 1: Heatmap of Means per Outcome Type ---\n",
    "print(\"-\" * 60)\n",
    "print(\"1) Heatmap of feature means per outcome\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(summary_df.T, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Feature Means by Prediction Outcome\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Plot 2: Comparison Bar Plot for One Feature at a Time ---\n",
    "# Choose top 5 most differing features (by std deviation across groups)\n",
    "print(\"-\" * 60)\n",
    "print(\"2) Bar Plots of each feature\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "top_diff_features = summary_df.std().sort_values(ascending=False).head(10).index\n",
    "\n",
    "for feature in top_diff_features:\n",
    "    print(feature + ' std deviation: ', summary_df[feature].std())\n",
    "    \n",
    "    # ax = summary_df[feature].plot(\n",
    "    #     kind=\"bar\", \n",
    "    #     title=f\"{feature} across Prediction Groups\", \n",
    "    #     ylabel=\"Mean Value\", \n",
    "    # )\n",
    "    ax = sns.barplot(\n",
    "        x=summary_df.index,\n",
    "        y=summary_df[feature].values,\n",
    "        hue=[\"True +\", \"True -\", \"False +\", \"False -\"],\n",
    "        palette=[\"green\", \"red\", \"gray\", \"gray\"],\n",
    "    )\n",
    "\n",
    "    # Add value labels above each bar\n",
    "    for i, value in enumerate(summary_df[feature]):\n",
    "        ax.text(i, value + 0.01, f\"{value:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "        \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f\"{feature} across Prediction Groups\")\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Plot 3: Radar Plot (optional, fancier) ---\n",
    "try:\n",
    "    from math import pi\n",
    "\n",
    "    categories = list(summary_norm.columns)\n",
    "    groups = summary_norm.index\n",
    "\n",
    "    for group in groups:\n",
    "        values = summary_norm.loc[group].tolist()\n",
    "        values += values[:1]  # repeat the first value to close the circle\n",
    "\n",
    "        angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]\n",
    "        angles += angles[:1]\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "        plt.xticks(angles[:-1], categories, color=\"grey\", size=8)\n",
    "\n",
    "        ax.plot(angles, values, linewidth=2, linestyle=\"solid\", label=group)\n",
    "        ax.fill(angles, values, alpha=0.2)\n",
    "\n",
    "        plt.title(f\"Radar Plot for {group}\", size=14, y=1.1)\n",
    "        plt.legend(loc=\"upper right\", bbox_to_anchor=(0.1, 0.1))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "except ImportError:\n",
    "    print(\"Radar plot skipped (requires polar plotting support).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pop-film     59.283000\n",
    "k-pop        56.952953\n",
    "chill        53.651000\n",
    "sad          52.379000\n",
    "grunge       49.594000\n",
    "indian       49.539000\n",
    "anime        48.772000\n",
    "emo          48.128000\n",
    "sertanejo    47.866000\n",
    "pop          47.576000\n",
    "\n",
    "[\"pop-film\", \"k-pop\", \"chill\", \"sad\", \"grunge\", \"indian\", \"anime\", \"emo\", \"sertanejo\", \"pop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: prettier style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# --- Genre Counts per Prediction Outcome ---\n",
    "\n",
    "# Ensure genre columns are all 0 or 1\n",
    "genre_cols = [col for col in df.columns if col.startswith(\"track_genre\")]\n",
    "\n",
    "# Define the prediction outcome groups\n",
    "groups = {\n",
    "    \"True Positives (H)\": true_positives,\n",
    "    \"True Negatives (S)\": true_negatives,\n",
    "    \"False Positives\": false_positives,\n",
    "    \"False Negatives\": false_negatives,\n",
    "}\n",
    "\n",
    "\n",
    "# Count genres per group\n",
    "genre_counts = {\n",
    "    group_name: (group_df[genre_cols]).astype(int).sum() for group_name, group_df in groups.items()\n",
    "}\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "genre_counts_df = pd.DataFrame(genre_counts).T  # Outcomes as rows\n",
    "# genre_counts_df.to_csv('output.csv', index=False)\n",
    "\n",
    "top_10_popular_genres = [\n",
    "    \"track_genre_pop-film\", \n",
    "    \"track_genre_k-pop\", \n",
    "    \"track_genre_chill\", \n",
    "    \"track_genre_sad\", \n",
    "    \"track_genre_grunge\", \n",
    "    \"track_genre_indian\", \n",
    "    \"track_genre_anime\", \n",
    "    \"track_genre_emo\", \n",
    "    \"track_genre_sertanejo\", \n",
    "    \"track_genre_pop\",\n",
    "    \"track_genre_indie\"\n",
    "]\n",
    "# top_genres = genre_counts_df.sum(axis=0).sort_values(ascending=False).index\n",
    "top_genres = genre_counts_df.sum(axis=0).sort_values(ascending=False).head(20).index\n",
    "\n",
    "def get_top_10_popular(genre):\n",
    "    if genre not in top_10_popular_genres: \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Plot barplot for each genre\n",
    "for genre in top_genres:\n",
    "    # if get_top_10_popular(genre): \n",
    "    #     continue\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    ax = sns.barplot(\n",
    "        x=genre_counts_df.index,\n",
    "        y=genre_counts_df[genre].values,\n",
    "        hue=[\"True +\", \"True -\", \"False +\", \"False -\"],\n",
    "        palette=[\"green\", \"red\", \"lightgreen\", \"lightcoral\"],\n",
    "    )\n",
    "\n",
    "    # Add value labels above bars\n",
    "    for i, value in enumerate(genre_counts_df[genre].values):\n",
    "        ax.text(i, value + 0.5, str(int(value)), ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "    plt.title(f\"Counts of {genre} by Prediction Outcome\")\n",
    "    plt.ylabel(\"Number of Tracks\")\n",
    "    plt.xlabel(\"Prediction Outcome\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(genre_counts_df[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of genres in true positives\n",
    "# print(true_negatives.columns.values)\n",
    "# genre_columns = [col for col in df.columns if col.startswith(\"track_genre_\")]\n",
    "# print(genre_columns)\n",
    "\n",
    "# # Step 2: Use idxmax to get the column name with value 1\n",
    "# df[\"track_genre\"] = df[genre_columns].idxmax(axis=1)\n",
    "\n",
    "# # Step 3: Remove the \"track_genre_\" prefix\n",
    "# df[\"track_genre\"] = df[\"track_genre\"].str.replace(\"track_genre_\", \"\")\n",
    "\n",
    "# # Optional: Drop one-hot columns\n",
    "# df = df.drop(columns=genre_columns)\n",
    "\n",
    "# mood_counts_by_genre = (\n",
    "#     df.groupby(\"track_genre\")[\"valence\"].value_counts().unstack().fillna(0)\n",
    "# )\n",
    "# true_negatives.to_csv(\"true_negatives.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of genres in true positives\n",
    "# print(true_negatives.columns.values)\n",
    "# genre_columns = [col for col in df.columns if col.startswith(\"track_genre_\")]\n",
    "# print(genre_columns)\n",
    "\n",
    "# # Step 2: Use idxmax to get the column name with value 1\n",
    "# df[\"track_genre\"] = df[genre_columns].idxmax(axis=1)\n",
    "\n",
    "# # Step 3: Remove the \"track_genre_\" prefix\n",
    "# df[\"track_genre\"] = df[\"track_genre\"].str.replace(\"track_genre_\", \"\")\n",
    "\n",
    "# # Optional: Drop one-hot columns\n",
    "# df = df.drop(columns=genre_columns)\n",
    "\n",
    "# mood_counts_by_genre = (\n",
    "#     df.groupby(\"track_genre\")[\"valence\"].value_counts().unstack().fillna(0)\n",
    "# )\n",
    "# true_negatives.to_csv(\"true_negatives.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(style=\"whitegrid\")\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# # df_no_genres = df.loc[:, ~df.columns.str.contains(\"track_genre\")]\n",
    "\n",
    "# # Features only (adjust as needed)\n",
    "# feature_cols = [\n",
    "#     col\n",
    "#     for col in df.columns\n",
    "#     if col\n",
    "#     not in [\n",
    "#         \"target_actual\",\n",
    "#         \"target_pred\",\n",
    "#         \"track_id\",\n",
    "#         \"artists\",\n",
    "#         \"album_name\",\n",
    "#         \"track_name\",\n",
    "#         \"valence\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# print(feature_cols)\n",
    "\n",
    "# # Mean summary per category\n",
    "# summary_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"False Negatives\": false_negatives[feature_cols].mean(),\n",
    "#         \"False Positives\": false_positives[feature_cols].mean(),\n",
    "#         \"True Positives\": true_positives[feature_cols].mean(),\n",
    "#         \"True Negatives\": true_negatives[feature_cols].mean(),\n",
    "#         # \"All Data\": df[feature_cols].mean(),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # Transpose for easier plotting\n",
    "# summary_df = summary_df.T\n",
    "\n",
    "# # Optional: Normalize columns for radar/spider-style plots\n",
    "# summary_norm = (summary_df - summary_df.min()) / (summary_df.max() - summary_df.min())\n",
    "\n",
    "\n",
    "# # --- Comparison Bar Plot for of each genre  ---\n",
    "# # Choose top 10 most differing features that are ONLY GENRES (by std deviation across groups)\n",
    "# top_diff_features = (\n",
    "#     summary_df.filter(like=\"track_genre\")\n",
    "#     .std()\n",
    "#     .sort_values(ascending=False)\n",
    "#     # .head(10)\n",
    "#     .index\n",
    "# )\n",
    "\n",
    "\n",
    "# for feature in top_diff_features:\n",
    "#     summary_df[feature].plot(\n",
    "#         kind=\"bar\", title=f\"{feature} across Prediction Groups\", ylabel=\"Mean Value\"\n",
    "#     )\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.grid(axis=\"y\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # --- Radar Plot (optional, fancier) ---\n",
    "# try:\n",
    "#     from math import pi\n",
    "\n",
    "#     categories = list(summary_norm.columns)\n",
    "#     groups = summary_norm.index\n",
    "\n",
    "#     for group in groups:\n",
    "#         values = summary_norm.loc[group].tolist()\n",
    "#         values += values[:1]  # repeat the first value to close the circle\n",
    "\n",
    "#         angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]\n",
    "#         angles += angles[:1]\n",
    "\n",
    "#         plt.figure(figsize=(6, 6))\n",
    "#         ax = plt.subplot(111, polar=True)\n",
    "#         plt.xticks(angles[:-1], categories, color=\"grey\", size=8)\n",
    "\n",
    "#         ax.plot(angles, values, linewidth=2, linestyle=\"solid\", label=group)\n",
    "#         ax.fill(angles, values, alpha=0.2)\n",
    "\n",
    "#         plt.title(f\"Radar Plot for {group}\", size=14, y=1.1)\n",
    "#         plt.legend(loc=\"upper right\", bbox_to_anchor=(0.1, 0.1))\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "# except ImportError:\n",
    "#     print(\"Radar plot skipped (requires polar plotting support).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using K-Nearest Neighbors with audio features to predict song valence, our model achieved a classification accuracy of 73.6%. The model performs slightly better at identifying low-valence (sadder) songs, with higher recall (79%) compared to high-valence (happier) songs (67%). Precision is fairly balanced across both classes. The findings suggest that features like danceability, energy, and acousticness have predictive value for estimating a song’s mood, but future work could explore better handling of class imbalance or using more sophisticated models to improve recall for high-valence tracks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
